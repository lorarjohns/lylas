{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import spacy\n",
    "from html import unescape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.read_csv(\"tech_jobs_nyc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.load('en')\n",
    "nlp = spacy.lang.en.English()\n",
    "\n",
    "def my_preprocessor(doc):\n",
    "    doc = doc.encode(\"latin-1\").decode(\"utf-8\")\n",
    "    doc = re.sub(r\"[\\d!@#$%^&*()\\\";:~`]\", \"\", doc)\n",
    "    return unescape(doc).lower()\n",
    "\n",
    "# tokenize the doc and lemmatize its tokens\n",
    "def my_tokenizer(doc):\n",
    "    tokens = nlp(doc)\n",
    "    return [token.text for token in tokens if not token.is_stop and not token.is_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(\n",
    "    #encoding='utf-8',\n",
    "    #decode_error='strict',\n",
    "    strip_accents=\"unicode\",\n",
    "    lowercase=True,\n",
    "    preprocessor=my_preprocessor, \n",
    "    tokenizer=my_tokenizer,\n",
    "    # analyzer='word', \n",
    "    #stop_words=\"english\",\n",
    "    token_pattern=r\"(?u)\\b[A-Za-z-\\'\\\"\\s][A-Za-z-\\'\\\"\\s]+\\b\", #[A-Za-z-\\'\\\"\\s][A-Za-z-\\'\\\"\\s]\n",
    "    ngram_range=(1, 2),\n",
    "    max_df=0.9,\n",
    "    min_df=2,\n",
    "    max_features=None,\n",
    "    #vocabulary=vect.vocabulary_\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "counts = cv.fit_transform(res_df['job_description'])\n",
    "lda = LDA(n_components=number_topics, n_jobs=-1)\n",
    "lda.fit(counts)\n",
    "\n",
    "dtm = vect.fit_transform(res_df['job_description'])\n",
    "feats = vect.get_feature_names()\n",
    "\n",
    "panel = pyLDAvis.sklearn.prepare(lda, dtm, cv, mds='tsne')\n",
    "pyLDAvis.save_html(panel, 'lda.html')"
   ]
  }
 ]
}